---
title: 简历
date: 2011-06-20 16:22:54
---

# **基本信息**

------

<div style="float:right">     <img src="my.jpg" width="180"> </div>

- **石振强**
- **男，92 生人**
- **山东科技大学 本硕**
- **中共党员**
- **13655422693(微信同号)**
- **4年工作经验**
- **已婚，现居青岛市北区**

# **教育背景**

------

**山东科技大学 本硕**

> -    **2011年9月至2015年7月   本科   计算机科学与技术**
>-    **2015年9月至2018年7月  研究生 人工智能–数据挖掘**
> 

**研究生课题介绍**

> 以教育数据挖掘为课题，针对在线教学平台的教育数据进行知识挖掘。主要分析平台上学习者的测评结果数据，详细挖掘了各类学习者的行为和产生此行为的原因。进一步针对不同类型的学习者的做题情况，提出了一种题目类型的描述方式，即由学习者的不同类别来对题目进行描述。通过对题目类型进行描述,我们可以更好的体现学习者与题目之间的关系。相对于仅把难度作为题目的分类标准，此次分类对于教学提供了极大的帮助。以此为基础，结合学习者的特征、做题情况、登录情况等，实现了不同阶段考试（期中、期末）的成绩等级预测，不同于以往的学习者成绩预测分析，研究学习者的特征时,加入了题目类型的因素,而且采用了多种分类算法进行组合。最后设计对比试验,验证了在学习者的特征中加入题目类型因素,可以提高模型的精度。以此，教学者可以根据预测结果，更早的预判学习者掌握情况，最终可以有的放矢，因材施教。
> 涉及模型算法包含聚类算法（kmeans）、集成学习算法(RandomTree, GBDT等)，模型精确度达90%以上。
>
> 在校期间成绩优异，多次获得校奖学金。曾获美国数学建模二等奖，软件著作权一项。

# **工作经历**

------

| 时间                 | 公司名称                 | 岗位             | 工作简介                                 |
| :------------------- | ------------------------ | ---------------- | ---------------------------------------- |
| 2017年8月-2017年11月 | 青岛智能研究院           | 研发岗           | 实习                                     |
| 2017年11月-2018年2月 | 高校信息产业股份有限公司 | 大数据算法实习岗 | 参与大数据平台的设计和数据挖掘算法的实现 |
| 2018年7月-至今       | 青岛中瑞汽车服务有限公司 | 大数据           | 车联网数据分析、金融风控                 |

# **项目经历**

------

**现担任PaaS工程组组长，负责大数据金融风控模型、客户私有云定制、车联网数据分析等ToB产品研发。**

## <kbd>金融风控数据系统</kbd>

> 金融风控评分卡模型是一个对贷中车辆风险评估的一个模型，主要以车联网数据为核心，为客户(金融保险、汽车租赁等客户)提供车辆的风险分数及等级，帮助客户实现有效的风险预判，及时规避风险。金融风控评分卡模型是一个基于多规则的混合模型，其输入是，全平台设备（900w+）、多种预警（7+）、各类特征(30+)、业务相关数据等，输出是每辆车的一个风险等级和风险分数。每日计算结果留存Hbase，hdfs存储文件用于历史计算 ，推送全量设备等级及分数至Kafka（部分为接口，部分为RocketMQ），由各业务部门消费并应用，已平稳运行2年+。
> 模型难点:依赖服务多、计算链路长、涉及数据源杂且数据纬度多。
> **负责内容**
> 一、相关服务开发
> 1、**风控评分卡模型（金融风控数据系统核心）**
> Python开发，自主协调各类相关预警数据的流入、处理、解析、计算及数据整合；
> MapReduce计算框架实现大批量离线计算，原来只计算近三个月安装的车辆，现可计算全平台数据；
> 关键阶段划分，链路长也可快速定位问题、任务重启幂等;
> 适应规则高频变更，将规则分为过滤、计算、二次计算及匹配等类型，使得计算逻辑模块可以按需调整应对模型规则变更。
> 2、聚集预警服务
> 帮助运营排查可疑风险聚集点（如黑区、拆车点、白名单等），设计实现了全量聚集(MapReduce)离线计算（T+1d）及小批量实时聚集查询功能(redis-geo)。
> 3、里程计算
> 全平台所有车量（900w+）每日里程数值(MapReduce)。
> 4、其他
> 如，常停点计算、实时黑区计算、用车频率计算，客户报表等
> 二、私有云部署
> 负责风控评分模型所有的依赖服务（20+）的客户定制化私有云部署，已经为平安金融租赁、吉致、安吉等公司部署完成。主要负责所有服务的依赖梳理、代码规范、配置规范、链接规范及个性化定制开发内容。通过前期沟通、规范设置、客户需求与服务梳理，使得团队人员快速交付客户的私有云部署。
> 三、其他
> 团队协作管理、多部门数据流转协调、应用部门(saas)数据对接等。

## <kbd>亿咖通车联网数据分析项目</kbd>

> 吉利下属子公司亿咖通的车辆数据分析项目，根据车辆上报信息，分析车辆的风险情况。目前也是公司在金融风控领域里，一个可供借鉴的行业应用典型案例。依托阿里云DataWorks来构建实时数据仓库和离线数仓，利用MaxCompute和Flink计算亿咖通车辆数据的特征及风险，方便客户借助结果数据进行研究及运营。其中使用MaxCompute离线特征计算，其中spark做离线计算，hive做离线存储，使用flink进行实时事件侦测并推送kafka，flink-sql将实时事件落库到实时数仓（hologres），使用dataflow工具进行数据同步(hive与hologres之间)，最终业务系统通过接口调用hologres中的数据进行产品应用。
> **负责内容** 
> 1、设计开发
> 负责整体架构落地，负责开发Flink实时计算模块。根据重要程度、耦合度、逻辑变更频率、上线影响范围等因素，主要将事件侦测（26+）分组为三大类，节省FLink资源的同时，减少因变更产生的风险。
> *核心事件:车辆的点火、启动、驻车、拖车等重要事件；*
> *故障侦测类: 机油、漏气、报警行驶、加油等9个故障事件侦测；*
> *维护侦测类: 轮胎充气、换机油、里程等维保类事件侦测。*
> 应项目紧急，FLink人员紧缺，经短暂学习Flink，并上手开发核心内容，因数据异常问题过多，多次自主试错反馈产品完善需求。通过使用Flink时间窗口模块及状态设计解决了事件实时侦测的计算；负责协调团队成员的离线数据计算模块开发，根据数据流转拆解任务，团队成员可并行开发，协调上下游数据计算的时间及人员调度。项目上线后运行平稳，验收过程顺利，所需资源及设计均符合架构要求。
> 2、交付
> 负责整个数据流转的文档格式定义、数据格式定义、部署及阶段性交付演示和最终交付演示等工作。

## <kbd>在线分析平台</kbd>

> 这是本人主导且参与全程设计(模型生命周期、前后端对接、前端页面设计及流转)的一个内部系统，起因是发现产品与开发在工作中的一些痛点（效率、规范、沟通等），与产品商讨后，进一步发现在数据整合、特征加工、规则（算法）模型、模型监控、模型治理等方面急需一个平台支持，最终确定开发一个在线分析实验平台，目的是规范流程、沉淀知识、积累数据资产。
> **负责系统设计及核心研发**
> 1、自定义规则的解析
> 2、模型异步运行及状态监控
> 3、后台数据流转、前端页面展示内容及流转、部分UI图标提供
> 亮点：
> 1、样本数据集（特征）展示方式由接口(Flask)定义，新增样本特征不新增多余页面。
> 2、策略人员编辑的规则解析成mongo查询语句、模型建立、计算结果比对均采用异步(Celery框架)进行，前端可显示任务状态，并可进行终止、编辑等操作，方便且可靠。
> 3、在小批量实验下，设置观测指标（不同等级、不同客户、门店等等），运行实验，快速对规则进行调整。
> 通过此系统，一方面策略人员需要编辑规则、计算结果等两天的工作量，可在系统中五分钟建立完成且根据效果不断校正阈值，节省了 小批量实验的时间成本。另一方面积累了数据资产、模型、有效特征、重要规则等重要成果。

## <kbd>车主画像</kbd>

> 为服务运营部门的业务，方便精准车主营销和分群，要对平台车主进行画像。
> 担任项目经理，梳理不同数据源的特征计算，由更为熟悉特定数据及相应计算方式的同事担任该数据源特征计算 ；负责设计数据流转和存储流程。通过配合开发完成200+数据特征的计算；负责开发车主画像系统，参与产品设计车主画像，标签统计，车主群像等核心功能。提出自定义标签、自定义分类及数据验证等功能，通过加入验证数据和人工分类，可以帮助产品及运营挖掘更多的业务场景，并且车主画像的闭环验证有极大的帮助。
> 
>涉及中间件:
> 
>- Python
> - Mongo(最新画像特征)
> - redis(慢查询快照)
> - hbase(历史数据查询接口)
> - hdfs(文件存储)
> - PostgreSQL(历史数据查询批量分析)

## <kbd>UBI车险模型</kbd>

> UBI是一个基于驾驶行为以及使用车辆相关数据相结合的个性化保险产品，不同于简单的里程计算和出险次数的车险评估，它更为准确、更为合理。UBI车险模型是通过挖掘车辆定位数据、车险情况、违章信息等，进一步挖掘车主潜在风险。通过模型结果，为金融保险客户提供更为全面的个性化风险评估，帮助客户及时规避不友好用户，减少损失。
> 负责客户需求解读、UBI调研、特征挖掘。最后通过决策树模型得到一个较好的模型效果。其中，通过**自主研究发现**，早高峰的定位点密集程度作为一个有效特征，从而提高了模型的召回率。最终与产品开发的规则模型相结合，提高了模型的鲁棒性。
> 如上模型均采用Python 的开源机器学习包-sklearn。

# **自我评价**

------



## **技能**

- **Python: 熟悉**
- **Linux: 熟练操作**
- **Flink: 熟悉**
- **Mapreduce：熟悉**
- **Java: 熟悉**
- **大数据组件、消息中间件: 熟练使用**
- **机器学习:  熟悉**
- **docker：了解**
- **postgre：了解**

------

## **软实力**

- **数据挖掘思维**
- **数据分析能力**
- **业务理解能力**
- **责任心强**
- **有一定的学习能力及沟通能力**
